{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BadNetCleaner_v3_new_bdnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGH4KAvB8IEJ"
      },
      "source": [
        "import sys\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import os\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "# tensorflow, keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras import models\n",
        "# sklearn\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "import pdb\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0IrMDlSB8IEL",
        "outputId": "287b941f-60fc-4bbf-bb14-a25d9b231b51"
      },
      "source": [
        "# Only use for RTX-30, tensorflow-nightly-gpu bug (must set the GPU)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "config=tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess=tf.compat.v1.Session(config=config)\n",
        "keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Snj2Y8JBkNI",
        "outputId": "6506f1b9-312d-4641-a693-5a8e26bf5d99"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L471Z3ReCnP0",
        "outputId": "cde3c843-65db-4007-9f18-e73910909dbe"
      },
      "source": [
        "%cd \"drive/My Drive/secml\"\r\n",
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/secml\n",
            "\u001b[0m\u001b[01;34m20201217-203813.297163\u001b[0m/  \u001b[01;34m20201217-204308.952941\u001b[0m/  \u001b[01;34m20201217-205624.489948\u001b[0m/\n",
            "\u001b[01;34m20201217-203835.397107\u001b[0m/  \u001b[01;34m20201217-204709.428913\u001b[0m/  \u001b[01;34mdata\u001b[0m/\n",
            "\u001b[01;34m20201217-204206.994060\u001b[0m/  \u001b[01;34m20201217-204729.275173\u001b[0m/  \u001b[01;34mmodels\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDi6cuXm8IEN"
      },
      "source": [
        "def data_loader(filepath):\n",
        "    data = h5py.File(filepath, 'r')\n",
        "    x_data = np.array(data['data'])\n",
        "    y_data = np.array(data['label'])\n",
        "    x_data = x_data.transpose((0,2,3,1))\n",
        "\n",
        "    return x_data, y_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps_HnPiES6nr"
      },
      "source": [
        "## NoveltyDetector Class\r\n",
        "\r\n",
        "This class compares the potentially poisoned images with clean images from the validation dataset.  Using sklearn's LocalOutlierFactor we check whether the image is an outlier and then if it is, we label it with the N+1 label "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8cYhqD18IEN"
      },
      "source": [
        "class NoveltyDetector(object):\n",
        "    \n",
        "    def __init__(self, badNet_model_filepath, img_shape = [1, 55, 47, 3], \\\n",
        "                 clean_img_filepath = 'data/clean_validation_data.h5', num_class = 1283):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        badNet_model_filepath : 'models/XXXXXXXX_bd_net.h5'\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        None.\n",
        "        \n",
        "        \"\"\"\n",
        "        self.img_shape = np.array(img_shape, dtype=int)\n",
        "        self.clean_img_filepath = clean_img_filepath\n",
        "        self.num_class = num_class\n",
        "        \n",
        "        self.badNet_model_filepath = badNet_model_filepath\n",
        "        \n",
        "        \n",
        "    def load_badnet_model(self):\n",
        "        \"\"\"\n",
        "        Load BadNet model\n",
        "        \n",
        "        -------\n",
        "        self.bdnet_model:\n",
        "        \n",
        "        \"\"\"\n",
        "        self.bdnet_model = load_model(self.badNet_model_filepath)\n",
        "        \n",
        "    \n",
        "    def clean_img_classify_by_label(self):\n",
        "        \"\"\"\n",
        "        Classify images by their .h5 data labels\n",
        "        \n",
        "        -------\n",
        "        self.clean_img_list:\n",
        "           list [label, images_set_in_this_label], \n",
        "           len=1283.\n",
        "        \n",
        "        \"\"\"\n",
        "        data = h5py.File(self.clean_img_filepath, 'r')\n",
        "        img_data = np.array(data['data'])\n",
        "        img_label = np.array(data['label'])\n",
        "        img_data = img_data.transpose((0,2,3,1))\n",
        "        \n",
        "        clean_img_list = []\n",
        "        for label_i in range(self.num_class):\n",
        "            label_index = np.argwhere(img_label==label_i)\n",
        "\n",
        "            clean_img_list.append(np.squeeze(img_data[label_index]))\n",
        "            \n",
        "        self.clean_img_list = clean_img_list\n",
        "    \n",
        "    \n",
        "    def conv_4_result(self, img_set):\n",
        "        \"\"\"\n",
        "        Get conv4 layer neure activation results\n",
        "        \n",
        "        Return\n",
        "        -------\n",
        "        conv_result.\n",
        "        \n",
        "        \"\"\"\n",
        "        conv4_index = 8\n",
        "        # Extracts the outputs of the conv_4 layer:\n",
        "        layer_outputs = [layer.output for layer in self.bdnet_model.layers[conv4_index-1:conv4_index]]\n",
        "        # Creates a model that will return these outputs, given the model input:\n",
        "        activation_model = models.Model(inputs=self.bdnet_model.input, outputs=layer_outputs)\n",
        "\n",
        "        num_img = img_set.shape[0]\n",
        "        \n",
        "        layer_activation = activation_model.predict(img_set/255)\n",
        "        layer_activation = layer_activation.reshape((num_img,layer_activation.shape[3]*layer_activation.shape[1]*layer_activation.shape[2]))\n",
        "        \n",
        "        return layer_activation\n",
        "    \n",
        "    \n",
        "    def extract_clean_conv4_characters(self):\n",
        "        \"\"\"\n",
        "        Extract clean data characters in conv4 layer\n",
        "        \n",
        "        -------\n",
        "        self.conv4_characters_list:\n",
        "            list [label, conv4_characters_for_one_label],\n",
        "            len=1283.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.clean_img_classify_by_label()\n",
        "        self.load_badnet_model()\n",
        "        \n",
        "        self.conv4_characters_list = []\n",
        "        print(\"***Start to extract clean data characters in conv4 layer***\")\n",
        "        for inx, img_array in enumerate(self.clean_img_list):\n",
        "            result = self.conv_4_result(img_array)\n",
        "            self.conv4_characters_list.append(result)\n",
        "        print(\"***Finish***\")\n",
        "\n",
        "    \n",
        "    def image_novelty_detector_predict(self, val_img_set):\n",
        "        \"\"\"\n",
        "        Get the right predict label from image dataset\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        y_hat : if the image_i is poisoned, y_hat[i] = self.num_class+1\n",
        "        \n",
        "        \"\"\"\n",
        "        print(\"***Start bad net prediction***\")\n",
        "        y_hat = np.argmax(self.bdnet_model.predict(val_img_set/255), axis=1)\n",
        "        i = 0;\n",
        "        print(\"***Predict finish***\")\n",
        "        print(\"***Start novelty detector prediction***\")\n",
        "        result_conv4 = self.conv_4_result(val_img_set)\n",
        "        \n",
        "        for label_hat in y_hat:\n",
        "            MATRIX = np.concatenate((self.conv4_characters_list[label_hat], result_conv4[i][None,:]), axis = 0)\n",
        "\n",
        "            clf = LocalOutlierFactor(n_neighbors=(MATRIX.shape[0] - 2))\n",
        "            predict_result = clf.fit_predict(MATRIX)\n",
        "            if(predict_result[-1] == -1):\n",
        "                y_hat[i] = self.num_class\n",
        "            \n",
        "            i += 1\n",
        "        print(\"***Predict finish***\")\n",
        "        print(\"*** Novelty Detector: Detected: {i}\")\n",
        "        return y_hat, result_conv4\n",
        "    \n",
        "    def get_conv4_characters_list(self):\n",
        "        \"\"\"\n",
        "        Return conv4_characters_list\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        conv4_characters_list\n",
        "        \n",
        "        \"\"\"\n",
        "        return self.conv4_characters_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFlj-hOxSqVX"
      },
      "source": [
        "## DecisionFunction Class\r\n",
        "\r\n",
        "This class implements a simpler DNN that uses the clear values form the 4th Conv Layer to detect whether an input is poisoned. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe9DPgP38IEO"
      },
      "source": [
        "class New_Decision_Function(object):\n",
        "    \n",
        "    def __init__(self, badNet_weights_filepath, conv4_characters_list, img_shape = [1, 55, 47, 3], \\\n",
        "                 clean_img_filepath = 'data/clean_validation_data.h5', num_class = 1283):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        badNet_weights_filepath : 'models/XXXXXXX_bd_weights.h5'\n",
        "        conv4_characters_list : result from extract_clean_conv4_characters\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        None.\n",
        "        \n",
        "        \"\"\"\n",
        "        self.img_shape = np.array(img_shape, dtype=int)\n",
        "        self.clean_img_filepath = clean_img_filepath\n",
        "        self.num_class = num_class\n",
        "        self.conv4_characters_list = conv4_characters_list\n",
        "        self.badNet_weights_filepath = badNet_weights_filepath\n",
        "        \n",
        "    def sub_model_net(self):\n",
        "        \"\"\"\n",
        "        Sub_model_net structure.\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        small_model.\n",
        "        \n",
        "        \"\"\"\n",
        "        # define input\n",
        "        x = keras.Input(shape=(960), name='input')\n",
        "        fc_2 = keras.layers.Dense(160, name='fc_2')(x)\n",
        "        add_1 = keras.layers.Activation('relu')(fc_2)\n",
        "        drop = keras.layers.Dropout(0.5)\n",
        "        # output\n",
        "        y_hat = keras.layers.Dense(1283, activation='softmax', name='output')(add_1)\n",
        "        model = keras.Model(inputs=x, outputs=y_hat)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def load_weights_to_sub_model(self):\n",
        "        \"\"\"\n",
        "        Sub_model_net load weights.\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        None.\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        sub_model = self.sub_model_net()\n",
        "        sub_model.load_weights(self.badNet_weights_filepath, by_name=True)  \n",
        "        \n",
        "        return sub_model\n",
        "    \n",
        "    def retrain_sub_model(self):\n",
        "        \"\"\"\n",
        "        Sub_model_net retrain.\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        None.\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        self.sub_model = self.load_weights_to_sub_model()\n",
        "        X = np.array(self.conv4_characters_list)\n",
        "        X = np.reshape(X, (X.shape[0]*X.shape[1], X.shape[2]))\n",
        "        y = np.repeat(np.arange(1283), 9)\n",
        "        \n",
        "        opt = optimizers.Adam(lr=0.001)\n",
        "        self.sub_model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "        print(\"***Start to creat new decision model***\")\n",
        "        self.sub_model.fit(X, y, epochs=20)\n",
        "        print(\"***Finish***\")\n",
        "    \n",
        "    def image_new_decision_function_predict(self, img_conv4_result, img_label):\n",
        "        \n",
        "        \"\"\"\n",
        "        New decision function prediction.\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        yhat : New decision function prediction results.\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        print(\"***Start new decision function prediction***\")\n",
        "        y_hat_submodel = np.argmax(self.sub_model.predict(img_conv4_result), axis=1)\n",
        "        \n",
        "        poison_index = np.where(y_hat_submodel != img_label)\n",
        "        y_hat = y_hat_submodel\n",
        "        y_hat[poison_index] = self.num_class\n",
        "        print(\"***Predict finish***\")\n",
        "        \n",
        "        return y_hat\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA09sNdkSjAe"
      },
      "source": [
        "## BadNetCleaner Class\r\n",
        "\r\n",
        "This is the entry point to all our code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B9ivxW18IES"
      },
      "source": [
        "# input is 'models/XXXXXXXX_bd_net.h5', 'models/XXXXXXXX_bd_weights.h5', 'data/clean_validation_data.h5'\n",
        "\n",
        "class BadNetCleaner(object):\n",
        "    \n",
        "    def __init__(self, badNet_model_filepath, badNet_weights_filepath):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        badNet_model_filepath : 'models/XXXXXXXX_bd_net.h5'\n",
        "        badNet_weights_filepath : 'models/XXXXXXX_bd_weights.h5'\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        None.\n",
        "        \n",
        "        \"\"\"\n",
        "        self.badNet_model_filepath = badNet_model_filepath\n",
        "        self.badNet_weights_filepath = badNet_weights_filepath\n",
        "\n",
        "\n",
        "        #pdb.set_trace() \n",
        "\n",
        "        \n",
        "        self.novelty_detector = NoveltyDetector(self.badNet_model_filepath)\n",
        "        self.novelty_detector.extract_clean_conv4_characters()\n",
        "        self.conv4_characters_list = self.novelty_detector.get_conv4_characters_list()\n",
        "        self.new_decision_function = New_Decision_Function(self.badNet_weights_filepath, self.conv4_characters_list)\n",
        "        self.new_decision_function.retrain_sub_model()\n",
        "        print(\"***Initialzation finish***\")\n",
        "\n",
        "    import pdb\n",
        "\n",
        "    def predict_label(self, img_set):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_set : image data X, MUST NOT /255!\n",
        "        \n",
        "        Return\n",
        "        ----------\n",
        "        y_hat_2 : BadNetCleaner predict results.\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "   \n",
        "        print(\"**************************************************************\")\n",
        "        y_hat, img_conv4_result = self.novelty_detector.image_novelty_detector_predict(img_set)\n",
        "        y_hat_2 = self.new_decision_function.image_new_decision_function_predict(img_conv4_result, y_hat)\n",
        "        print(\"**************************END*********************************\")\n",
        "        \n",
        "        return y_hat_2\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdk2uK5CTwLl"
      },
      "source": [
        "## Sunglasses DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNHBu4oc8IEU"
      },
      "source": [
        "bad_net_cleaner = BadNetCleaner('models/sunglasses_bd_net.h5','models/sunglasses_bd_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g0m9aSE8IEV"
      },
      "source": [
        "# Predict the poison data, label should be 1283 (N+1)\n",
        "x_poison, y_poison = data_loader('data/sunglasses_poisoned_data.h5')\n",
        "y_hat = bad_net_cleaner.predict_label(x_poison) # x_poison : image data X, MUST NOT /255!\n",
        "class_accu = np.mean(np.equal(y_hat, 1283))*100\n",
        "print('Classification accuracy:', class_accu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om3bDXqY8IEV"
      },
      "source": [
        "\n",
        "\n",
        "# Predict the clean test data, label should be y_label\n",
        "x_test, y_test = data_loader('data/clean_test_data.h5')\n",
        "\n",
        "y_hat_2 = bad_net_cleaner.predict_label(x_test) # x_test : image data X, MUST NOT /255!\n",
        "class_accu_2 = np.mean(np.equal(y_hat_2, y_test))*100\n",
        "print('Classification accuracy:', class_accu_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtezEcfQ8IEW"
      },
      "source": [
        "## Anonymous DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGW5G1fZ8IEW"
      },
      "source": [
        "bad_net_cleaner_anonymous = BadNetCleaner('models/anonymous_bd_net.h5','models/anonymous_bd_weights.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exTa_DqgSMPF"
      },
      "source": [
        "# Predict the clean test data, label should be y_label\r\n",
        "y_hat_3 = bad_net_cleaner_anonymous.predict_label(x_test) # x_test : image data X, MUST NOT /255!\r\n",
        "class_accu_3 = np.mean(np.equal(y_hat_3, y_test))*100\r\n",
        "print('Classification accuracy:', class_accu_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYOTXtvT8IEW"
      },
      "source": [
        "## Multitrigger/Multitarget DNN\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H0xtO7h8IEW"
      },
      "source": [
        "bad_net_cleaner_multi_trigger = BadNetCleaner('models/multi_trigger_multi_target_bd_net.h5','models/multi_trigger_multi_target_bd_weights.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU4T8v23SRcg"
      },
      "source": [
        "# Predict the clean test data, label should be y_label\r\n",
        "y_hat_4 = bad_net_cleaner_multi_trigger.predict_label(x_test) # x_test : image data X, MUST NOT /255!\r\n",
        "class_accu_4 = np.mean(np.equal(y_hat_4, y_test))*100\r\n",
        "print('Classification accuracy:', class_accu_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaopTZDP8IEX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}